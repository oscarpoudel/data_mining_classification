{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e75be61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 22:38:37.508762: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-06 22:38:37.512867: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-06 22:38:37.524010: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743993517.542932 2954621 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743993517.549408 2954621 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743993517.563394 2954621 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743993517.563417 2954621 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743993517.563420 2954621 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743993517.563423 2954621 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-06 22:38:37.568406: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tqdm.notebook import tqdm  # Use tqdm for progress visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821d7967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " gender                 0\n",
      "age                    0\n",
      "hypertension           0\n",
      "heart_disease          0\n",
      "smoking_history        0\n",
      "bmi                    0\n",
      "HbA1c_level            0\n",
      "blood_glucose_level    0\n",
      "diabetes               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Load and Preprocess Data\n",
    "df = pd.read_csv(\"./diabetes_prediction_dataset.csv\")  \n",
    "df.drop_duplicates(inplace=True)\n",
    "print(\"Missing values in each column:\\n\", df.isna().sum())\n",
    "categorical_columns = [\"gender\", \"smoking_history\"]\n",
    "le_dict = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    le_dict[col] = le\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(\"diabetes\", axis=1)\n",
    "y = df[\"diabetes\"]\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#  Conv1D deep learning model reshaping the input to (samples, time_steps, channels)\n",
    "X_dl = X_scaled.reshape((X_scaled.shape[0], X_scaled.shape[1], 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "228de0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Model Definitions\n",
    "# Random Forest Model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# SVM Model\n",
    "svm_model = SVC(kernel='linear', probability=True, random_state=42)\n",
    "\n",
    "# Conv1D Deep Learning Model\n",
    "def create_conv1d_model(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=input_shape),\n",
    "        tf.keras.layers.Conv1D(filters=32, kernel_size=2, activation='relu'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eb09055",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Metrics Calculation Function\n",
    "def calculate_metrics(cm):\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    TPR = TP / (TP + FN) if (TP + FN) > 0 else 0  \n",
    "    FPR = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "    FNR = FN / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    TSS = TPR - FPR  \n",
    "    denominator = ((TP + FN) * (FN + TN) + (TP + FP) * (FP + TN))\n",
    "    HSS = 2 * (TP * TN - FN * FP) / denominator if denominator != 0 else 0\n",
    "    return {\"accuracy\": accuracy, \"TPR\": TPR, \"FPR\": FPR, \"FNR\": FNR, \"TSS\": TSS, \"HSS\": HSS,\n",
    "            \"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e344c1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest Model:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d3870ea2484a7787af6cb1c4318f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RF CV:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 RF training time: 4.828195 seconds\n",
      "Fold 2 RF training time: 4.747567 seconds\n",
      "Fold 3 RF training time: 4.663944 seconds\n",
      "Fold 4 RF training time: 4.769497 seconds\n",
      "Fold 5 RF training time: 4.896482 seconds\n",
      "Fold 6 RF training time: 4.779871 seconds\n",
      "Fold 7 RF training time: 4.857546 seconds\n",
      "Fold 8 RF training time: 5.295923 seconds\n",
      "Fold 9 RF training time: 5.237453 seconds\n",
      "Fold 10 RF training time: 5.330139 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. KFold Cross-Validation Setup\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store metrics for each model across folds\n",
    "rf_metrics_list = []\n",
    "svm_metrics_list = []\n",
    "conv1d_metrics_list = []\n",
    "\n",
    "# 5. Training and Evaluation using KFold with tqdm\n",
    "print(\"Training Random Forest Model:\")\n",
    "for i, (train_index, test_index) in enumerate(tqdm(kf.split(X), total=n_splits, desc=\"RF CV\"), start=1):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Measure training time\n",
    "    start_time = time.time()\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    print(f\"Fold {i} RF training time: {train_time:.6f} seconds\")\n",
    "    \n",
    "    # Prediction and metrics calculation\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    rf_metrics_list.append(calculate_metrics(cm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8430c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SVM Model:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529e77a7b1b94574af0944ccb29f1b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SVM CV:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 SVM training time: 235.199971 seconds\n",
      "Fold 2 SVM training time: 210.981436 seconds\n",
      "Fold 3 SVM training time: 231.348896 seconds\n",
      "Fold 4 SVM training time: 152.992190 seconds\n",
      "Fold 5 SVM training time: 168.868646 seconds\n",
      "Fold 6 SVM training time: 154.605697 seconds\n",
      "Fold 7 SVM training time: 157.822639 seconds\n",
      "Fold 8 SVM training time: 149.309565 seconds\n",
      "Fold 9 SVM training time: 147.865381 seconds\n",
      "Fold 10 SVM training time: 138.212827 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nTraining SVM Model:\")\n",
    "for i, (train_index, test_index) in enumerate(tqdm(kf.split(X), total=n_splits, desc=\"SVM CV\"), start=1):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    print(f\"Fold {i} SVM training time: {train_time:.6f} seconds\")\n",
    "    \n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    svm_metrics_list.append(calculate_metrics(cm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23efb411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Conv1D Model:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a11709d1f64fb2aa131a7af84c8a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conv1D CV:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1743995332.869811 2954621 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1743995332.870680 2954621 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Conv1D training time: 125.798733 seconds\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step\n",
      "Fold 2 Conv1D training time: 132.645822 seconds\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step\n",
      "Fold 3 Conv1D training time: 124.719298 seconds\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step\n",
      "Fold 4 Conv1D training time: 139.025658 seconds\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nTraining Conv1D Model:\")\n",
    "for i, (train_index, test_index) in enumerate(tqdm(kf.split(X), total=n_splits, desc=\"Conv1D CV\"), start=1):\n",
    "    X_train_dl, X_test_dl = X_dl[train_index], X_dl[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Create a new model instance for each fold to ensure fresh weights\n",
    "    model = create_conv1d_model((X_train_dl.shape[1], 1))\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train_dl, y_train, epochs=20, batch_size=16, verbose=0)\n",
    "    train_time = time.time() - start_time\n",
    "    print(f\"Fold {i} Conv1D training time: {train_time:.6f} seconds\")\n",
    "    \n",
    "    y_pred = (model.predict(X_test_dl) > 0.5).astype(\"int32\").flatten()\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    conv1d_metrics_list.append(calculate_metrics(cm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab34d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. Aggregate and Display Results per Fold and Overall\n",
    "def display_fold_metrics(model_name, metrics_list):\n",
    "    df_folds = pd.DataFrame(metrics_list)\n",
    "    print(f\"\\n{model_name} Metrics for Each Fold:\")\n",
    "    display(df_folds)  \n",
    "    \n",
    "    # Calculate overall average metrics\n",
    "    overall_avg = df_folds.mean()\n",
    "    print(f\"\\n{model_name} Overall Average Metrics (10-Fold CV):\")\n",
    "    display(overall_avg.to_frame().transpose())  \n",
    "\n",
    "# Display metrics \n",
    "display_fold_metrics(\"Random Forest\", rf_metrics_list)\n",
    "display_fold_metrics(\"SVM\", svm_metrics_list)\n",
    "display_fold_metrics(\"Conv1D\", conv1d_metrics_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab1120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine overall averages into one comparison table\n",
    "overall_results = pd.DataFrame({\n",
    "    \"Random Forest\": pd.DataFrame(rf_metrics_list).mean(),\n",
    "    \"SVM\": pd.DataFrame(svm_metrics_list).mean(),\n",
    "    \"Conv1D\": pd.DataFrame(conv1d_metrics_list).mean()\n",
    "}).transpose()\n",
    "\n",
    "print(\"\\nComparison of Overall Average Metrics for All Models:\")\n",
    "display(overall_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_mi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
